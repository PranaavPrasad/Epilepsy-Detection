{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b346976",
   "metadata": {},
   "source": [
    "# Phase 2: EEG Data Preprocessing\n",
    "## CHB-MIT Dataset - Data Cleaning and Feature Extraction\n",
    "\n",
    "This notebook preprocesses EEG data from selected subjects (5-6) for model training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d4085d",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b7a7be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Libraries imported\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# EEG processing\n",
    "import mne\n",
    "from scipy import signal\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "# Data storage\n",
    "import h5py\n",
    "import joblib\n",
    "\n",
    "print(\"✓ Libraries imported\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a7479c",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93e060c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Directory: c:\\Users\\Pranaav_Prasad\\OneDrive\\Desktop\\Projects\\Epilepsy-Detection\n",
      "Selected Subjects: ['chb01', 'chb02', 'chb03', 'chb05', 'chb24']\n",
      "Sampling Rate: 256 Hz → 64 Hz (downsampled 4x)\n",
      "Window: 4s with 3s overlap (256 samples)\n",
      "High overlap strategy: Maximize seizure windows via overlapping\n",
      "Target ratio: 1:10 (Seizure:Normal)\n",
      "Expected dataset size: ~1 GB\n"
     ]
    }
   ],
   "source": [
    "# Paths\n",
    "BASE_DIR = Path(r\"c:\\Users\\Pranaav_Prasad\\OneDrive\\Desktop\\Projects\\Epilepsy-Detection\")\n",
    "RAW_DATA_DIR = BASE_DIR / \"data\" / \"raw\" / \"chb-mit-scalp-eeg-database-1.0.0\"\n",
    "PROCESSED_DATA_DIR = BASE_DIR / \"data\" / \"processed\"\n",
    "\n",
    "# Selected subjects (top 6 with most seizures)\n",
    "SELECTED_SUBJECTS = ['chb01', 'chb02', 'chb03', 'chb05', 'chb24']\n",
    "\n",
    "# EEG parameters - OPTIMIZED FOR IMBALANCED LEARNING\n",
    "ORIGINAL_SAMPLING_RATE = 256  # Hz (original)\n",
    "SAMPLING_RATE = 64  # Hz (downsampled 4x - still captures seizure patterns <30 Hz)\n",
    "DOWNSAMPLE_FACTOR = ORIGINAL_SAMPLING_RATE // SAMPLING_RATE\n",
    "WINDOW_SIZE = 4  # seconds (shorter windows = more samples)\n",
    "OVERLAP = 3  # seconds (HIGH overlap for seizures to create more positive examples)\n",
    "N_SAMPLES_PER_WINDOW = SAMPLING_RATE * WINDOW_SIZE  # 256 samples\n",
    "\n",
    "# Balancing strategy\n",
    "TARGET_IMBALANCE_RATIO = 10  # 1:10 (Seizure:Normal) - practical for deep learning\n",
    "# This gives us more training data while keeping imbalance manageable for focal loss\n",
    "\n",
    "# Frequency bands\n",
    "FREQ_BANDS = {\n",
    "    'delta': (0.5, 4),\n",
    "    'theta': (4, 8),\n",
    "    'alpha': (8, 13),\n",
    "    'beta': (13, 30)\n",
    "}\n",
    "\n",
    "print(f\"Base Directory: {BASE_DIR}\")\n",
    "print(f\"Selected Subjects: {SELECTED_SUBJECTS}\")\n",
    "print(f\"Sampling Rate: {ORIGINAL_SAMPLING_RATE} Hz → {SAMPLING_RATE} Hz (downsampled {DOWNSAMPLE_FACTOR}x)\")\n",
    "print(f\"Window: {WINDOW_SIZE}s with {OVERLAP}s overlap ({N_SAMPLES_PER_WINDOW} samples)\")\n",
    "print(f\"High overlap strategy: Maximize seizure windows via overlapping\")\n",
    "print(f\"Target ratio: 1:{TARGET_IMBALANCE_RATIO} (Seizure:Normal)\")\n",
    "print(f\"Expected dataset size: ~1 GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e65eb44",
   "metadata": {},
   "source": [
    "## 3. Parse Summary Files for Seizure Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eab23807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chb01: 7 seizure events (442s total)\n",
      "chb02: 3 seizure events (172s total)\n",
      "chb03: 7 seizure events (402s total)\n",
      "chb05: 5 seizure events (558s total)\n",
      "chb24: 16 seizure events (511s total)\n",
      "\n",
      "✓ Loaded seizure information\n",
      "Total seizure duration across all subjects: 2085s (34.8 minutes)\n",
      "Note: Actual window ratio will be calculated after processing\n"
     ]
    }
   ],
   "source": [
    "def parse_summary_file(summary_path):\n",
    "    \"\"\"Extract seizure information from subject summary file.\"\"\"\n",
    "    seizure_info = []\n",
    "    \n",
    "    with open(summary_path, 'r') as f:\n",
    "        content = f.read()\n",
    "        lines = content.split('\\n')\n",
    "        \n",
    "        current_file = None\n",
    "        for i, line in enumerate(lines):\n",
    "            if 'File Name:' in line:\n",
    "                current_file = line.split(':')[1].strip()\n",
    "            elif 'Seizure Start Time:' in line and current_file:\n",
    "                start_time = int(line.split(':')[1].strip().split()[0])\n",
    "                # Find end time in next line\n",
    "                if i + 1 < len(lines) and 'Seizure End Time:' in lines[i + 1]:\n",
    "                    end_time = int(lines[i + 1].split(':')[1].strip().split()[0])\n",
    "                    seizure_info.append({\n",
    "                        'file': current_file,\n",
    "                        'start': start_time,\n",
    "                        'end': end_time\n",
    "                    })\n",
    "    \n",
    "    return seizure_info\n",
    "\n",
    "# Load seizure information for selected subjects\n",
    "seizure_data = {}\n",
    "total_seizure_duration = 0\n",
    "for subject in SELECTED_SUBJECTS:\n",
    "    summary_file = RAW_DATA_DIR / subject / f\"{subject}-summary.txt\"\n",
    "    if summary_file.exists():\n",
    "        seizure_data[subject] = parse_summary_file(summary_file)\n",
    "        subject_duration = sum([sz['end'] - sz['start'] for sz in seizure_data[subject]])\n",
    "        total_seizure_duration += subject_duration\n",
    "        print(f\"{subject}: {len(seizure_data[subject])} seizure events ({subject_duration}s total)\")\n",
    "\n",
    "print(f\"\\n✓ Loaded seizure information\")\n",
    "print(f\"Total seizure duration across all subjects: {total_seizure_duration}s ({total_seizure_duration/60:.1f} minutes)\")\n",
    "print(f\"Note: Actual window ratio will be calculated after processing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8109ca50",
   "metadata": {},
   "source": [
    "## 4. Preprocessing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eee1e9bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Preprocessing functions defined (with augmentation for seizures)\n"
     ]
    }
   ],
   "source": [
    "def preprocess_eeg(raw_data, sampling_rate=256, target_rate=128):\n",
    "    \"\"\"Apply bandpass filter, downsample, and normalization.\"\"\"\n",
    "    # Bandpass filter (0.5-50 Hz)\n",
    "    nyquist = sampling_rate / 2\n",
    "    low, high = 0.5 / nyquist, 50 / nyquist\n",
    "    b, a = signal.butter(4, [low, high], btype='band')\n",
    "    filtered = signal.filtfilt(b, a, raw_data, axis=1)\n",
    "    \n",
    "    # Downsample to save space (256 Hz -> 128 Hz)\n",
    "    if sampling_rate > target_rate:\n",
    "        downsample_factor = sampling_rate // target_rate\n",
    "        filtered = filtered[:, ::downsample_factor]\n",
    "    \n",
    "    # Normalization (z-score)\n",
    "    mean = np.mean(filtered, axis=1, keepdims=True)\n",
    "    std = np.std(filtered, axis=1, keepdims=True)\n",
    "    normalized = (filtered - mean) / (std + 1e-8)\n",
    "    \n",
    "    return normalized\n",
    "\n",
    "def augment_seizure_window(window_data):\n",
    "    \"\"\"Augment seizure windows with slight variations to balance dataset.\"\"\"\n",
    "    augmented = []\n",
    "    \n",
    "    # Original\n",
    "    augmented.append(window_data)\n",
    "    \n",
    "    # Time shift (circular shift by 10% of window)\n",
    "    shift_amount = window_data.shape[1] // 10\n",
    "    shifted = np.roll(window_data, shift_amount, axis=1)\n",
    "    augmented.append(shifted)\n",
    "    \n",
    "    # Add small noise (0.05 std)\n",
    "    noise = np.random.normal(0, 0.05, window_data.shape)\n",
    "    noisy = window_data + noise\n",
    "    augmented.append(noisy)\n",
    "    \n",
    "    return augmented\n",
    "\n",
    "def extract_spectral_features(data, sampling_rate, freq_bands):\n",
    "    \"\"\"Extract power in frequency bands.\"\"\"\n",
    "    features = []\n",
    "    \n",
    "    for ch_data in data:\n",
    "        freqs, psd = signal.welch(ch_data, fs=sampling_rate, nperseg=256)\n",
    "        \n",
    "        ch_features = []\n",
    "        for band_name, (low, high) in freq_bands.items():\n",
    "            idx = np.logical_and(freqs >= low, freqs <= high)\n",
    "            band_power = np.mean(psd[idx])\n",
    "            ch_features.append(band_power)\n",
    "        \n",
    "        features.extend(ch_features)\n",
    "    \n",
    "    return np.array(features)\n",
    "\n",
    "def extract_statistical_features(data):\n",
    "    \"\"\"Extract statistical features from each channel.\"\"\"\n",
    "    features = []\n",
    "    \n",
    "    for ch_data in data:\n",
    "        features.extend([\n",
    "            np.mean(ch_data),\n",
    "            np.std(ch_data),\n",
    "            skew(ch_data),\n",
    "            kurtosis(ch_data),\n",
    "            np.max(ch_data) - np.min(ch_data)  # range\n",
    "        ])\n",
    "    \n",
    "    return np.array(features)\n",
    "\n",
    "print(\"✓ Preprocessing functions defined (with augmentation for seizures)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b9a1e9",
   "metadata": {},
   "source": [
    "## 5. Process EEG Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c29308a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ EDF processing function defined\n"
     ]
    }
   ],
   "source": [
    "def process_edf_file(edf_path, seizure_times=None):\n",
    "    \"\"\"Process single EDF file and extract windows.\"\"\"\n",
    "    raw = mne.io.read_raw_edf(str(edf_path), preload=True, verbose=False)\n",
    "    data = raw.get_data()\n",
    "    \n",
    "    # Preprocess\n",
    "    data = preprocess_eeg(data, SAMPLING_RATE)\n",
    "    \n",
    "    # Create sliding windows\n",
    "    n_channels, n_samples = data.shape\n",
    "    step_size = (WINDOW_SIZE - OVERLAP) * SAMPLING_RATE\n",
    "    \n",
    "    windows = []\n",
    "    labels = []\n",
    "    \n",
    "    for start_idx in range(0, n_samples - N_SAMPLES_PER_WINDOW, step_size):\n",
    "        end_idx = start_idx + N_SAMPLES_PER_WINDOW\n",
    "        window_data = data[:, start_idx:end_idx]\n",
    "        \n",
    "        # Determine label\n",
    "        window_time_start = start_idx / SAMPLING_RATE\n",
    "        window_time_end = end_idx / SAMPLING_RATE\n",
    "        \n",
    "        is_seizure = False\n",
    "        if seizure_times:\n",
    "            for sz in seizure_times:\n",
    "                if (window_time_start >= sz['start'] and window_time_start < sz['end']) or \\\n",
    "                   (window_time_end > sz['start'] and window_time_end <= sz['end']):\n",
    "                    is_seizure = True\n",
    "                    break\n",
    "        \n",
    "        windows.append(window_data)\n",
    "        labels.append(1 if is_seizure else 0)\n",
    "    \n",
    "    return np.array(windows), np.array(labels)\n",
    "\n",
    "print(\"✓ EDF processing function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbba8c18",
   "metadata": {},
   "source": [
    "## 6. Process All Selected Subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9a7e4cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing with SMART IMBALANCED LEARNING (1:10 ratio)...\n",
      "\n",
      "Selected subjects: ['chb01', 'chb02', 'chb03', 'chb05', 'chb24']\n",
      "Strategy: High overlap for seizures + contextual negatives + smart undersampling\n",
      "\n",
      "PHASE 1: Collecting windows with high overlap...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d01ea9ae7a9a45ee883a95c302932dbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Subjects:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "chb01: Processing 42 files...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0369ae9949754d8cafdb853aa70cf1b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  chb01:   0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "chb02: Processing 36 files...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d602ec9070f48aa895f8adeb66f3ac1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  chb02:   0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "chb03: Processing 38 files...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2ce03a34c1e432fa5ae7d4f448c1dc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  chb03:   0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "chb05: Processing 39 files...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bac53132e35f4b1a97656d103a04d352",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  chb05:   0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "chb24: Processing 22 files...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ca03edc26a84cd4bb78a1d35e0411d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  chb24:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "PHASE 2: Smart balancing...\n",
      "Collected: 2181 seizures, 4427 contextual, 613943 far normals\n",
      "Balanced: 2181 seizures, 21810 normals\n",
      "  - Contextual normals: 4427\n",
      "  - Random normals: 17383\n",
      "Ratio: 1:10.0\n",
      "\n",
      "Writing 23991 windows to HDF5...\n",
      "\n",
      "======================================================================\n",
      "✓ SMART IMBALANCED DATASET PROCESSING COMPLETE\n",
      "======================================================================\n",
      "Total files processed: 177\n",
      "Total windows: 23,991\n",
      "Seizure windows: 2,181 (9.09%)\n",
      "Normal windows: 21,810 (90.91%)\n",
      "Seizure:Normal ratio: 1:10.0\n",
      "======================================================================\n",
      "\n",
      "Saved to: c:\\Users\\Pranaav_Prasad\\OneDrive\\Desktop\\Projects\\Epilepsy-Detection\\data\\processed\\preprocessed_data.h5\n",
      "File size: 0.49 GB\n",
      "\n",
      "======================================================================\n",
      "✓ SMART IMBALANCED DATASET PROCESSING COMPLETE\n",
      "======================================================================\n",
      "Total files processed: 177\n",
      "Total windows: 23,991\n",
      "Seizure windows: 2,181 (9.09%)\n",
      "Normal windows: 21,810 (90.91%)\n",
      "Seizure:Normal ratio: 1:10.0\n",
      "======================================================================\n",
      "\n",
      "Saved to: c:\\Users\\Pranaav_Prasad\\OneDrive\\Desktop\\Projects\\Epilepsy-Detection\\data\\processed\\preprocessed_data.h5\n",
      "File size: 0.49 GB\n"
     ]
    }
   ],
   "source": [
    "# Memory-efficient processing: Stream data directly to HDF5\n",
    "# STRATEGY: Smart imbalanced learning with 1:10 ratio\n",
    "# Key optimizations:\n",
    "# 1. HIGH OVERLAP (3s) for seizure windows → maximize positive examples\n",
    "# 2. SMART UNDERSAMPLING of normals → keep contextual negatives (pre/post seizure)\n",
    "# 3. Target ratio 1:10 (manageable for Focal Loss, enough data for deep learning)\n",
    "# 4. Label window as positive if ANY seizure sample present\n",
    "# 5. Target: ~1GB dataset with ~20K-40K windows\n",
    "\n",
    "output_file = PROCESSED_DATA_DIR / \"preprocessed_data.h5\"\n",
    "\n",
    "print(\"Processing with SMART IMBALANCED LEARNING (1:10 ratio)...\\n\")\n",
    "print(f\"Selected subjects: {SELECTED_SUBJECTS}\")\n",
    "print(f\"Strategy: High overlap for seizures + contextual negatives + smart undersampling\\n\")\n",
    "\n",
    "# Initialize counters\n",
    "total_windows = 0\n",
    "total_seizure = 0\n",
    "total_files = 0\n",
    "\n",
    "# Temporary storage for balancing\n",
    "all_seizure_windows = []\n",
    "all_normal_windows = []\n",
    "contextual_normal_windows = []  # Pre/post seizure windows (keep all)\n",
    "\n",
    "# Create HDF5 file\n",
    "with h5py.File(output_file, 'w') as hdf:\n",
    "    first_write = True\n",
    "    \n",
    "    # PHASE 1: Collect all windows with contextual awareness\n",
    "    print(\"PHASE 1: Collecting windows with high overlap...\")\n",
    "    for subject in tqdm(SELECTED_SUBJECTS, desc=\"Subjects\"):\n",
    "        subject_path = RAW_DATA_DIR / subject\n",
    "        if not subject_path.exists():\n",
    "            print(f\"\\n  ⚠ Skipping {subject} - directory not found\")\n",
    "            continue\n",
    "            \n",
    "        edf_files = sorted([f for f in subject_path.glob(\"*.edf\") if not f.name.endswith('+')])\n",
    "        seizure_info = seizure_data.get(subject, [])\n",
    "        \n",
    "        print(f\"\\n{subject}: Processing {len(edf_files)} files...\")\n",
    "        \n",
    "        for edf_file in tqdm(edf_files, desc=f\"  {subject}\", leave=False):\n",
    "            try:\n",
    "                file_seizures = [s for s in seizure_info if s['file'] == edf_file.name]\n",
    "                \n",
    "                raw = mne.io.read_raw_edf(str(edf_file), preload=False, verbose=False)\n",
    "                \n",
    "                # Process in chunks\n",
    "                chunk_duration = 300  # 5 minutes per chunk\n",
    "                total_duration = raw.times[-1]\n",
    "                n_chunks = int(np.ceil(total_duration / chunk_duration))\n",
    "                \n",
    "                for chunk_idx in range(n_chunks):\n",
    "                    start_time = chunk_idx * chunk_duration\n",
    "                    end_time = min((chunk_idx + 1) * chunk_duration, total_duration)\n",
    "                    \n",
    "                    start_sample = int(start_time * ORIGINAL_SAMPLING_RATE)\n",
    "                    stop_sample = int(end_time * ORIGINAL_SAMPLING_RATE)\n",
    "                    \n",
    "                    data = raw.get_data(start=start_sample, stop=stop_sample)\n",
    "                    data = preprocess_eeg(data, ORIGINAL_SAMPLING_RATE, SAMPLING_RATE).astype(np.float32)\n",
    "                    \n",
    "                    n_channels, n_samples = data.shape\n",
    "                    step_size = int((WINDOW_SIZE - OVERLAP) * SAMPLING_RATE)\n",
    "                    \n",
    "                    for start_idx in range(0, n_samples - N_SAMPLES_PER_WINDOW + 1, step_size):\n",
    "                        end_idx = start_idx + N_SAMPLES_PER_WINDOW\n",
    "                        window_data = data[:, start_idx:end_idx]\n",
    "                        \n",
    "                        window_time_start = start_time + (start_idx / SAMPLING_RATE)\n",
    "                        window_time_end = start_time + (end_idx / SAMPLING_RATE)\n",
    "                        \n",
    "                        # Label as positive if ANY overlap with seizure\n",
    "                        is_seizure = False\n",
    "                        is_contextual = False  # Near seizure (±60s)\n",
    "                        \n",
    "                        if file_seizures:\n",
    "                            for sz in file_seizures:\n",
    "                                # Check for seizure overlap\n",
    "                                if (window_time_start >= sz['start'] and window_time_start < sz['end']) or \\\n",
    "                                   (window_time_end > sz['start'] and window_time_end <= sz['end']) or \\\n",
    "                                   (window_time_start <= sz['start'] and window_time_end >= sz['end']):\n",
    "                                    is_seizure = True\n",
    "                                    break\n",
    "                                \n",
    "                                # Check if contextual (within ±60s of seizure)\n",
    "                                if not is_seizure:\n",
    "                                    if (window_time_start >= sz['start'] - 60 and window_time_start <= sz['end'] + 60) or \\\n",
    "                                       (window_time_end >= sz['start'] - 60 and window_time_end <= sz['end'] + 60):\n",
    "                                        is_contextual = True\n",
    "                        \n",
    "                        if is_seizure:\n",
    "                            all_seizure_windows.append(window_data)\n",
    "                        elif is_contextual:\n",
    "                            contextual_normal_windows.append(window_data)\n",
    "                        else:\n",
    "                            all_normal_windows.append(window_data)\n",
    "                    \n",
    "                    del data\n",
    "                \n",
    "                total_files += 1\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"\\n  ⚠ Error processing {edf_file.name}: {str(e)[:80]}\")\n",
    "                continue\n",
    "    \n",
    "    # PHASE 2: Smart balancing with contextual negatives\n",
    "    print(f\"\\n\\nPHASE 2: Smart balancing...\")\n",
    "    print(f\"Collected: {len(all_seizure_windows)} seizures, {len(contextual_normal_windows)} contextual, {len(all_normal_windows)} far normals\")\n",
    "    \n",
    "    n_seizures = len(all_seizure_windows)\n",
    "    target_normals = n_seizures * TARGET_IMBALANCE_RATIO\n",
    "    \n",
    "    # Keep ALL contextual windows (important for learning)\n",
    "    selected_normals = contextual_normal_windows.copy()\n",
    "    remaining_slots = target_normals - len(selected_normals)\n",
    "    \n",
    "    # Fill remaining with random far normals\n",
    "    if remaining_slots > 0 and len(all_normal_windows) > 0:\n",
    "        np.random.seed(42)\n",
    "        n_to_sample = min(remaining_slots, len(all_normal_windows))\n",
    "        normal_indices = np.random.choice(len(all_normal_windows), size=n_to_sample, replace=False)\n",
    "        selected_normals.extend([all_normal_windows[i] for i in normal_indices])\n",
    "    \n",
    "    print(f\"Balanced: {n_seizures} seizures, {len(selected_normals)} normals\")\n",
    "    print(f\"  - Contextual normals: {len(contextual_normal_windows)}\")\n",
    "    print(f\"  - Random normals: {len(selected_normals) - len(contextual_normal_windows)}\")\n",
    "    print(f\"Ratio: 1:{len(selected_normals)/n_seizures:.1f}\")\n",
    "    \n",
    "    # Combine and shuffle\n",
    "    all_windows = all_seizure_windows + selected_normals\n",
    "    all_labels = [1] * n_seizures + [0] * len(selected_normals)\n",
    "    \n",
    "    # Shuffle\n",
    "    combined = list(zip(all_windows, all_labels))\n",
    "    np.random.shuffle(combined)\n",
    "    all_windows, all_labels = zip(*combined)\n",
    "    \n",
    "    # Write to HDF5\n",
    "    print(f\"\\nWriting {len(all_windows)} windows to HDF5...\")\n",
    "    windows = np.array(all_windows, dtype=np.float32)\n",
    "    labels = np.array(all_labels, dtype=np.int8)\n",
    "    \n",
    "    hdf.create_dataset('X', data=windows, \n",
    "                      compression='gzip', compression_opts=4)\n",
    "    hdf.create_dataset('y', data=labels,\n",
    "                      compression='gzip', compression_opts=4)\n",
    "    \n",
    "    total_windows = len(windows)\n",
    "    total_seizure = np.sum(labels)\n",
    "    \n",
    "    # Save metadata\n",
    "    if 'X' in hdf:\n",
    "        hdf.attrs['n_samples'] = hdf['X'].shape[0]\n",
    "        hdf.attrs['n_channels'] = hdf['X'].shape[1]\n",
    "        hdf.attrs['window_size'] = WINDOW_SIZE\n",
    "        hdf.attrs['sampling_rate'] = SAMPLING_RATE\n",
    "        hdf.attrs['subjects'] = ','.join(SELECTED_SUBJECTS)\n",
    "        hdf.attrs['total_files_processed'] = total_files\n",
    "\n",
    "if total_windows > 0:\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"✓ SMART IMBALANCED DATASET PROCESSING COMPLETE\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"Total files processed: {total_files}\")\n",
    "    print(f\"Total windows: {total_windows:,}\")\n",
    "    print(f\"Seizure windows: {total_seizure:,} ({total_seizure/total_windows*100:.2f}%)\")\n",
    "    print(f\"Normal windows: {total_windows - total_seizure:,} ({(total_windows-total_seizure)/total_windows*100:.2f}%)\")\n",
    "    print(f\"Seizure:Normal ratio: 1:{(total_windows-total_seizure)/max(1,total_seizure):.1f}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"\\nSaved to: {output_file}\")\n",
    "    print(f\"File size: {output_file.stat().st_size / (1024**3):.2f} GB\")\n",
    "else:\n",
    "    print(\"\\n✗ No data processed - check for errors above\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83593ca",
   "metadata": {},
   "source": [
    "## 8. Save Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "825cf165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verifying c:\\Users\\Pranaav_Prasad\\OneDrive\\Desktop\\Projects\\Epilepsy-Detection\\data\\processed\\preprocessed_data.h5...\n",
      "\n",
      "Available datasets: ['X', 'y']\n",
      "Available attributes: ['n_channels', 'n_samples', 'sampling_rate', 'subjects', 'total_files_processed', 'window_size']\n",
      "\n",
      "Data shapes:\n",
      "  X: (23991, 23, 256) (samples, channels, time_points)\n",
      "  y: (23991,) (samples,)\n",
      "\n",
      "Class distribution:\n",
      "  Seizure (1): 2181 (9.09%)\n",
      "  Normal (0): 21810 (90.91%)\n",
      "\n",
      "Data statistics:\n",
      "  X dtype: float32\n",
      "  X range: [-45.386, 44.584]\n",
      "  X mean: 0.000\n",
      "Data shapes:\n",
      "  X: (23991, 23, 256) (samples, channels, time_points)\n",
      "  y: (23991,) (samples,)\n",
      "\n",
      "Class distribution:\n",
      "  Seizure (1): 2181 (9.09%)\n",
      "  Normal (0): 21810 (90.91%)\n",
      "\n",
      "Data statistics:\n",
      "  X dtype: float32\n",
      "  X range: [-45.386, 44.584]\n",
      "  X mean: 0.000\n",
      "  X std: 1.069\n",
      "\n",
      "Preprocessed data verified successfully!\n",
      "  X std: 1.069\n",
      "\n",
      "Preprocessed data verified successfully!\n"
     ]
    }
   ],
   "source": [
    "# Verify the saved data\n",
    "output_file = PROCESSED_DATA_DIR / \"preprocessed_data.h5\"\n",
    "print(f\"Verifying {output_file}...\\n\")\n",
    "\n",
    "with h5py.File(output_file, 'r') as f:\n",
    "    print(f\"Available datasets: {list(f.keys())}\")\n",
    "    print(f\"Available attributes: {list(f.attrs.keys())}\\n\")\n",
    "    \n",
    "    if 'X' in f:\n",
    "        X_data = f['X'][:]\n",
    "        y_data = f['y'][:]\n",
    "        \n",
    "        print(f\"Data shapes:\")\n",
    "        print(f\"  X: {X_data.shape} (samples, channels, time_points)\")\n",
    "        print(f\"  y: {y_data.shape} (samples,)\")\n",
    "        print(f\"\\nClass distribution:\")\n",
    "        print(f\"  Seizure (1): {np.sum(y_data == 1)} ({np.sum(y_data == 1) / len(y_data) * 100:.2f}%)\")\n",
    "        print(f\"  Normal (0): {np.sum(y_data == 0)} ({np.sum(y_data == 0) / len(y_data) * 100:.2f}%)\")\n",
    "        print(f\"\\nData statistics:\")\n",
    "        print(f\"  X dtype: {X_data.dtype}\")\n",
    "        print(f\"  X range: [{X_data.min():.3f}, {X_data.max():.3f}]\")\n",
    "        print(f\"  X mean: {X_data.mean():.3f}\")\n",
    "        print(f\"  X std: {X_data.std():.3f}\")\n",
    "        \n",
    "        print(f\"\\nPreprocessed data verified successfully!\")\n",
    "    else:\n",
    "        print(\"ERROR: No data found in HDF5 file!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976ede41",
   "metadata": {},
   "source": [
    "## 9. Summary\n",
    "\n",
    "**Preprocessing Complete:**\n",
    "- Filtered EEG signals (0.5-50 Hz bandpass)\n",
    "- Normalized data (z-score)\n",
    "- Created sliding windows (4s with 2s overlap)\n",
    "- Labeled windows as seizure/normal\n",
    "- Balanced dataset\n",
    "- Saved processed data for training\n",
    "\n",
    "**Next: Phase 3 - Model Training**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
